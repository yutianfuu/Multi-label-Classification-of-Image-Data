{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training_with_unlabelled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs7mOJvd9bV3"
      },
      "source": [
        "Use unlabelled train set with prediction label to train.\n",
        "</br>\n",
        "We previously randomly choose 3000 instances from the unlabelled set and predict them so that they have labels. Now we will use these samples with our original labelled train set to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy8yh4NUD6yr",
        "outputId": "206705fd-1a13-45c4-96d2-a255dc04c0fc"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1AbxjCBByF-xGV3c7FJ1ztZC1HO0O0uJ0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AbxjCBByF-xGV3c7FJ1ztZC1HO0O0uJ0\n",
            "To: /content/kaggle.json\n",
            "\r  0% 0.00/66.0 [00:00<?, ?B/s]\r100% 66.0/66.0 [00:00<00:00, 133kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1C3pEk_D7sz",
        "outputId": "8e3170b5-5135-4128-cb1d-bb7da1a2c29d"
      },
      "source": [
        "! pip install kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "! kaggle competitions download -c comp-551-fall-2021\n",
        "! unzip images_l.pkl.zip\n",
        "! unzip images_test.pkl.zip\n",
        "! unzip images_ul.pkl.zip\n",
        "! unzip labels_l.pkl.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading images_test.pkl.zip to /content\n",
            " 85% 84.0M/99.0M [00:00<00:00, 145MB/s]\n",
            "100% 99.0M/99.0M [00:00<00:00, 166MB/s]\n",
            "Downloading images_ul.pkl.zip to /content\n",
            " 90% 178M/198M [00:00<00:00, 194MB/s]\n",
            "100% 198M/198M [00:01<00:00, 202MB/s]\n",
            "Downloading images_l.pkl.zip to /content\n",
            " 98% 193M/197M [00:00<00:00, 218MB/s]\n",
            "100% 197M/197M [00:00<00:00, 217MB/s]\n",
            "Downloading labels_l.pkl.zip to /content\n",
            "  0% 0.00/141k [00:00<?, ?B/s]\n",
            "100% 141k/141k [00:00<00:00, 145MB/s]\n",
            "Archive:  images_l.pkl.zip\n",
            "  inflating: images_l.pkl            \n",
            "Archive:  images_test.pkl.zip\n",
            "  inflating: images_test.pkl         \n",
            "Archive:  images_ul.pkl.zip\n",
            "  inflating: images_ul.pkl           \n",
            "Archive:  labels_l.pkl.zip\n",
            "  inflating: labels_l.pkl            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OptbegmD84h"
      },
      "source": [
        "import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU, ZeroPadding2D,Convolution2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import History\n",
        "from tensorflow.keras.optimizers import Nadam, Adam, SGD\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.resnet import ResNet152, ResNet101, ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras import layers, regularizers, Input\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Z2rr-OD_fi"
      },
      "source": [
        "# Image data for training (30,000 sample, each sample is a 56x56 image)\n",
        "# train_labels = pd.read_csv('train_max_y.csv')\n",
        "# train_images = pd.read_pickle('train_max_x')\n",
        "# test_images = pd.read_pickle('test_max_x')\n",
        "with open(\"images_l.pkl\", 'rb') as f:\n",
        "    # load into as a numpy array\n",
        "    train_labelled_data = pickle.load(f)\n",
        "# Test images. The prediction corresponding to these images should be uploaded. (15,000 samples)\n",
        "with open(\"images_test.pkl\", 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "# Labels for training (30,000 rows, each row is a size 36 binary vector, which is the label to the corresponding image)\n",
        "with open(\"labels_l.pkl\", 'rb') as f:\n",
        "    train_labelled_y = pickle.load(f)\n",
        "# Additional images that can be used for training the classifier.\n",
        "# Labels for these images are not provided. (30,000 samples, where each sample is a 56x56 image)\n",
        "with open(\"images_ul.pkl\", 'rb') as f:\n",
        "    train_unlabelled_x = pickle.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3anGZFV9EBk0"
      },
      "source": [
        "# processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xHpRdhPUEIv",
        "outputId": "b8efad3e-84a6-49e7-a12e-3a0f1b6de946"
      },
      "source": [
        "# load already process train, test data\n",
        "! gdown https://drive.google.com/uc?id=1wyUpGYONbWRjdaLgeiEH2ryqm_kMOMF_\n",
        "! gdown https://drive.google.com/uc?id=1tFt0ddczfNPmq8IUNnZ8ifGUbgzP9DxU\n",
        "! gdown https://drive.google.com/uc?id=1bOq70mP5ghxfiFtbK3rTbPDcefkxgyQx\n",
        "! gdown https://drive.google.com/uc?id=1oSJM0BtYu_hiJ7mkSNphJLAmBVnznO4o"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wyUpGYONbWRjdaLgeiEH2ryqm_kMOMF_\n",
            "To: /content/processed_train_set.csv\n",
            "100% 386M/386M [00:01<00:00, 214MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tFt0ddczfNPmq8IUNnZ8ifGUbgzP9DxU\n",
            "To: /content/processed_test_set.csv\n",
            "100% 193M/193M [00:00<00:00, 204MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bOq70mP5ghxfiFtbK3rTbPDcefkxgyQx\n",
            "To: /content/processed_ul_train_set.csv\n",
            "100% 386M/386M [00:01<00:00, 227MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oSJM0BtYu_hiJ7mkSNphJLAmBVnznO4o\n",
            "To: /content/ul_train_label.csv\n",
            "100% 216k/216k [00:00<00:00, 63.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AIqa8UVEn51"
      },
      "source": [
        "# Digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpZ8bM0UEpWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19d1151-75e7-4834-c7f9-260826ce2fdc"
      },
      "source": [
        "def cnn():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    vgg16 =  VGG16(weights='imagenet', include_top=False, input_shape=(56,56,3))\n",
        "    #res = ResNet152(weights='imagenet', include_top=False, input_shape=(56,56,3))\n",
        "# des = DenseNet169(weights='imagenet', include_top=False, input_shape=(56,56,3))\n",
        "    model.add(vgg16)\n",
        "# model.add(des)\n",
        "# model.add(res)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1000, activation='relu'))\n",
        "    # model.add(Dropout(0.5))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(lr=0.0001),metrics=['accuracy'])\n",
        "    # Compile\n",
        "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = cnn()\n",
        "model.summary() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              513000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,237,698\n",
            "Trainable params: 15,237,698\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnOaMNRIUPMb"
      },
      "source": [
        "Digit prediction is noise senstitive, so need to use clear_noise data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePjhHwO6Ery5"
      },
      "source": [
        "train_labelled_x=np.array(pd.DataFrame(pd.read_csv('processed_train_set.csv')))\n",
        "train_labelled_x=train_labelled_x.reshape((30000,56,56))\n",
        "train_unlabelled_x = np.array(pd.DataFrame(pd.read_csv('processed_ul_train_set.csv')))\n",
        "train_unlabelled_x = train_unlabelled_x.reshape((30000,56,56))\n",
        "train_unlabelled_x = train_unlabelled_x[0:3000]\n",
        "train_unlabelled_y = np.array(pd.DataFrame(pd.read_csv('ul_train_label.csv')))\n",
        "\n",
        "train_labelled_x = np.concatenate((train_unlabelled_x,train_labelled_x),axis=0)\n",
        "train_labelled_y = np.concatenate((train_unlabelled_y,train_labelled_y),axis=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0BFn5Y4Etvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4a89d6-f6b0-4450-c23e-274b8703e8fa"
      },
      "source": [
        "x_train = train_labelled_x\n",
        "y_train = train_labelled_y\n",
        "for i in range(x_train.shape[0]):\n",
        "  x_train[i] = (x_train[i]>200).astype('int32')*255\n",
        "import torch\n",
        "\n",
        "x_train = torch.Tensor(x_train)\n",
        "x_train = torch.unsqueeze(x_train, dim=3)/255.\n",
        "x_train = x_train.repeat(1,1,1,3)\n",
        "x_train = x_train.numpy()\n",
        "x_train = x_train.astype('float32')\n",
        "x_valid = x_train[29500:30000, :]\n",
        "x_train = x_train[:29500, :]\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_valid shape:', x_valid.shape)\n",
        "\n",
        "# y_train = keras.utils.to_categorical(y_train, 10)\n",
        "a = y_train\n",
        "y_valid = y_train[29500:30000, :10]\n",
        "y_train = y_train[:29500, :10]\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_valid shape:', y_valid.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (29500, 56, 56, 3)\n",
            "x_valid shape: (500, 56, 56, 3)\n",
            "y_train shape: (29500, 10)\n",
            "y_valid shape: (500, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oIcCSfqEwap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2807fe5-f88a-48a6-9d3a-a0e057fe1429"
      },
      "source": [
        "for i in range(25):\n",
        "  print('Trail: ',i)\n",
        "  history = model.fit(x_train, y_train, batch_size=100, epochs=1, verbose=1)\n",
        "  score = model.evaluate(x_valid, y_valid, verbose=1)\n",
        "  model.save('VGG16_2_SP_{}'.format(i))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trail:  0\n",
            "295/295 [==============================] - 28s 61ms/step - loss: 1.1649 - accuracy: 0.6594\n",
            "16/16 [==============================] - 1s 23ms/step - loss: 0.4255 - accuracy: 0.8800\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_0/assets\n",
            "Trail:  1\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.7290 - accuracy: 0.8299\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3319 - accuracy: 0.9280\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_1/assets\n",
            "Trail:  2\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.6461 - accuracy: 0.8584\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2810 - accuracy: 0.9440\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_2/assets\n",
            "Trail:  3\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.5893 - accuracy: 0.8732\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3154 - accuracy: 0.9280\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_3/assets\n",
            "Trail:  4\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.5439 - accuracy: 0.8830\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3027 - accuracy: 0.9100\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_4/assets\n",
            "Trail:  5\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.4905 - accuracy: 0.8942\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2793 - accuracy: 0.9320\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_5/assets\n",
            "Trail:  6\n",
            "295/295 [==============================] - 18s 61ms/step - loss: 0.4465 - accuracy: 0.8999\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3161 - accuracy: 0.9240\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_6/assets\n",
            "Trail:  7\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.3838 - accuracy: 0.9088\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3557 - accuracy: 0.9140\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_7/assets\n",
            "Trail:  8\n",
            "295/295 [==============================] - 18s 61ms/step - loss: 0.3129 - accuracy: 0.9192\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3672 - accuracy: 0.9140\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_8/assets\n",
            "Trail:  9\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.2542 - accuracy: 0.9283\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4439 - accuracy: 0.9060\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_9/assets\n",
            "Trail:  10\n",
            "295/295 [==============================] - 18s 61ms/step - loss: 0.2020 - accuracy: 0.9402\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3925 - accuracy: 0.9060\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_10/assets\n",
            "Trail:  11\n",
            "295/295 [==============================] - 18s 61ms/step - loss: 0.1576 - accuracy: 0.9518\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4529 - accuracy: 0.8820\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_11/assets\n",
            "Trail:  12\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.1233 - accuracy: 0.9608\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4409 - accuracy: 0.9000\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_12/assets\n",
            "Trail:  13\n",
            "295/295 [==============================] - 18s 61ms/step - loss: 0.0965 - accuracy: 0.9696\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5310 - accuracy: 0.8820\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_13/assets\n",
            "Trail:  14\n",
            "295/295 [==============================] - 18s 61ms/step - loss: 0.0698 - accuracy: 0.9781\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5129 - accuracy: 0.8960\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_14/assets\n",
            "Trail:  15\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0595 - accuracy: 0.9817\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5321 - accuracy: 0.8800\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_15/assets\n",
            "Trail:  16\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0489 - accuracy: 0.9844\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4497 - accuracy: 0.9080\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_16/assets\n",
            "Trail:  17\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0443 - accuracy: 0.9869\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5013 - accuracy: 0.9040\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_17/assets\n",
            "Trail:  18\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0422 - accuracy: 0.9876\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5331 - accuracy: 0.8820\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_18/assets\n",
            "Trail:  19\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0357 - accuracy: 0.9891\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4406 - accuracy: 0.9060\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_19/assets\n",
            "Trail:  20\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0290 - accuracy: 0.9917\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4757 - accuracy: 0.9200\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_20/assets\n",
            "Trail:  21\n",
            "295/295 [==============================] - 18s 61ms/step - loss: 0.0314 - accuracy: 0.9907\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4467 - accuracy: 0.8960\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_21/assets\n",
            "Trail:  22\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0414 - accuracy: 0.9870\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4948 - accuracy: 0.8860\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_22/assets\n",
            "Trail:  23\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0285 - accuracy: 0.9920\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6298 - accuracy: 0.8940\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_23/assets\n",
            "Trail:  24\n",
            "295/295 [==============================] - 18s 62ms/step - loss: 0.0278 - accuracy: 0.9913\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5532 - accuracy: 0.9000\n",
            "INFO:tensorflow:Assets written to: VGG16_2_SP_24/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ii5-5J7UfgM"
      },
      "source": [
        "load processed test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEZtrk7MEzyp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "17718a10-a590-4997-99d8-161cfe39279d"
      },
      "source": [
        "# load testing data for model testing\n",
        "x_test=np.array(pd.DataFrame(pd.read_csv('processed_test_set.csv')))\n",
        "\n",
        "x_test=x_test.reshape((15000,56,56))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "plt.imshow(x_test[random.randint(0,14999)], cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# with open(\"images_test.pkl\",'rb') as f:\n",
        "#   x_test = pickle.load(f)\n",
        "for i in range(x_test.shape[0]):\n",
        "  x_test[i] = (x_test[i]>200).astype('int32')*255\n",
        "x_test = torch.Tensor(x_test)\n",
        "x_test = torch.unsqueeze(x_test,dim=3)/255\n",
        "x_test = x_test.repeat(1,1,1,3)\n",
        "x_test = x_test.numpy()\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIAarrjyE1RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e09f76-7281-46e7-831a-d98fc2e5cd8d"
      },
      "source": [
        "result = model.predict(x_test,verbose=1)\n",
        "result = np.argmax(result, axis = 1)\n",
        "print(result[0:10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 4s 9ms/step\n",
            "[0 4 9 0 6 9 3 2 1 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjuzNQ2sE3lr"
      },
      "source": [
        "# Letter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfYFQhfVE3Fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f9f893-a742-411f-91fb-206efb6df2be"
      },
      "source": [
        "def cnn2():\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(56, 56, 1)))\n",
        "  model.add(Conv2D(filters= 56, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(Conv2D(filters= 56, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.6))\n",
        "\n",
        "  model.add(Conv2D(filters= 128, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(Conv2D(filters= 128, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.6))\n",
        "\n",
        "  model.add(Conv2D(filters= 256, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(Conv2D(filters= 256, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.6))\n",
        "\n",
        "  model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.6))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.6))\n",
        "  model.add(Dense(26, activation='softmax'))\n",
        "  model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "model2=cnn2()\n",
        "model2.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 56, 56, 56)        560       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 56, 56, 56)        28280     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 56, 56, 56)       224       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 28, 28, 56)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28, 28, 56)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       64640     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 28, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 7, 7, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              4719616   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 26)                26650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,420,450\n",
            "Trainable params: 9,416,498\n",
            "Non-trainable params: 3,952\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_hj_76gFJBD"
      },
      "source": [
        "# # reload train data for model2 training\n",
        "# train_labelled_x=np.array(pd.DataFrame(pd.read_csv('processed_train_set.csv')))\n",
        "\n",
        "# train_labelled_x=train_labelled_x.reshape((30000,56,56))\n",
        "\n",
        "with open(\"images_l.pkl\", 'rb') as f:\n",
        "    # load into as a numpy array\n",
        "    train_labelled_data = pickle.load(f)\n",
        "\n",
        "# Labels for training (30,000 rows, each row is a size 36 binary vector, which is the label to the corresponding image)\n",
        "with open(\"labels_l.pkl\", 'rb') as f:\n",
        "    train_labelled_y = pickle.load(f)\n",
        "\n",
        "with open(\"images_ul.pkl\", 'rb') as f:\n",
        "    train_unlabelled_x = pickle.load(f)\n",
        "\n",
        "train_labelled_x = train_labelled_data\n",
        "\n",
        "train_unlabelled_x = train_unlabelled_x[0:3000]\n",
        "train_unlabelled_y = np.array(pd.DataFrame(pd.read_csv('ul_train_label.csv')))\n",
        "\n",
        "train_labelled_x = np.concatenate((train_unlabelled_x,train_labelled_x),axis=0)\n",
        "train_labelled_y = np.concatenate((train_unlabelled_y,train_labelled_y),axis=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxgEshIFMMp"
      },
      "source": [
        "letter_train = train_labelled_x.reshape(-1, 56, 56, 1)\n",
        "# letter_train /= 255\n",
        "letter_train_label = train_labelled_y[:, 10:]\n",
        "x_train2 = letter_train[:29000,:,:,:]\n",
        "y_train2 = letter_train_label[:29000,:]\n",
        "x_valid2 = letter_train[29000:,:,:,:]\n",
        "y_valid2 = letter_train_label[29000:,:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0GUOhGzFNyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f8dafe-6209-49a9-f325-2532f01361ad"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_dense_1_accuracy', patience=2, verbose=1,factor=0.8, min_lr=0.000001)\n",
        "history = model2.fit(x_train2, y_train2, epochs=40, batch_size=128,\n",
        "          validation_data=(x_valid2, y_valid2), \n",
        "          callbacks=[reduce_lr], shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "227/227 [==============================] - ETA: 0s - loss: 4.1275 - accuracy: 0.0685WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 17s 64ms/step - loss: 4.1275 - accuracy: 0.0685 - val_loss: 15.9727 - val_accuracy: 0.0355 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 3.4887 - accuracy: 0.0930WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 13s 59ms/step - loss: 3.4882 - accuracy: 0.0931 - val_loss: 3.1136 - val_accuracy: 0.1080 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 3.1384 - accuracy: 0.1265WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 3.1380 - accuracy: 0.1264 - val_loss: 3.0328 - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 2.8883 - accuracy: 0.1673WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 2.8874 - accuracy: 0.1674 - val_loss: 3.6716 - val_accuracy: 0.1095 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 2.5598 - accuracy: 0.2470WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 2.5586 - accuracy: 0.2473 - val_loss: 4.5459 - val_accuracy: 0.1093 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 2.2373 - accuracy: 0.3449WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 2.2359 - accuracy: 0.3452 - val_loss: 3.0980 - val_accuracy: 0.2278 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.9382 - accuracy: 0.4387WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.9365 - accuracy: 0.4390 - val_loss: 2.4229 - val_accuracy: 0.3640 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.7218 - accuracy: 0.5167WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.7201 - accuracy: 0.5171 - val_loss: 1.8582 - val_accuracy: 0.4762 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.5334 - accuracy: 0.5773WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.5321 - accuracy: 0.5776 - val_loss: 1.1672 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.4348 - accuracy: 0.6100WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.4328 - accuracy: 0.6104 - val_loss: 0.9044 - val_accuracy: 0.7347 - lr: 0.0010\n",
            "Epoch 11/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.2916 - accuracy: 0.6549WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.2901 - accuracy: 0.6553 - val_loss: 0.8867 - val_accuracy: 0.7365 - lr: 0.0010\n",
            "Epoch 12/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.1811 - accuracy: 0.6897WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.1791 - accuracy: 0.6901 - val_loss: 0.5213 - val_accuracy: 0.8342 - lr: 0.0010\n",
            "Epoch 13/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.1144 - accuracy: 0.7161WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.1128 - accuracy: 0.7165 - val_loss: 0.4725 - val_accuracy: 0.8537 - lr: 0.0010\n",
            "Epoch 14/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.0650 - accuracy: 0.7288WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.0637 - accuracy: 0.7290 - val_loss: 0.4650 - val_accuracy: 0.8635 - lr: 0.0010\n",
            "Epoch 15/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 1.0067 - accuracy: 0.7525WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 1.0054 - accuracy: 0.7528 - val_loss: 0.5144 - val_accuracy: 0.8485 - lr: 0.0010\n",
            "Epoch 16/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.9623 - accuracy: 0.7634WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.9607 - accuracy: 0.7639 - val_loss: 0.4547 - val_accuracy: 0.8690 - lr: 0.0010\n",
            "Epoch 17/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.9000 - accuracy: 0.7754WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.8984 - accuracy: 0.7758 - val_loss: 0.4833 - val_accuracy: 0.8600 - lr: 0.0010\n",
            "Epoch 18/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.9012 - accuracy: 0.7840WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.8998 - accuracy: 0.7843 - val_loss: 0.2491 - val_accuracy: 0.9220 - lr: 0.0010\n",
            "Epoch 19/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.8766 - accuracy: 0.7889WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.8752 - accuracy: 0.7891 - val_loss: 0.4792 - val_accuracy: 0.8765 - lr: 0.0010\n",
            "Epoch 20/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.8439 - accuracy: 0.7989WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.8425 - accuracy: 0.7992 - val_loss: 0.2653 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 21/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.8145 - accuracy: 0.8048WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.8131 - accuracy: 0.8051 - val_loss: 0.2489 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 22/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.8083 - accuracy: 0.8090WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.8066 - accuracy: 0.8094 - val_loss: 0.5356 - val_accuracy: 0.8643 - lr: 0.0010\n",
            "Epoch 23/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.7866 - accuracy: 0.8165WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.7851 - accuracy: 0.8168 - val_loss: 0.4880 - val_accuracy: 0.8727 - lr: 0.0010\n",
            "Epoch 24/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.7527 - accuracy: 0.8171WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.7511 - accuracy: 0.8175 - val_loss: 0.5423 - val_accuracy: 0.8577 - lr: 0.0010\n",
            "Epoch 25/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.7316 - accuracy: 0.8246WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 61ms/step - loss: 0.7303 - accuracy: 0.8250 - val_loss: 0.4515 - val_accuracy: 0.8823 - lr: 0.0010\n",
            "Epoch 26/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.7592 - accuracy: 0.8262WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.7580 - accuracy: 0.8264 - val_loss: 0.2348 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 27/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.7467 - accuracy: 0.8261WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.7451 - accuracy: 0.8264 - val_loss: 0.4245 - val_accuracy: 0.8875 - lr: 0.0010\n",
            "Epoch 28/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.7464 - accuracy: 0.8305WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.7450 - accuracy: 0.8309 - val_loss: 0.1935 - val_accuracy: 0.9408 - lr: 0.0010\n",
            "Epoch 29/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.7166 - accuracy: 0.8381WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.7155 - accuracy: 0.8383 - val_loss: 0.2016 - val_accuracy: 0.9398 - lr: 0.0010\n",
            "Epoch 30/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.8390WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6933 - accuracy: 0.8393 - val_loss: 0.2258 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 31/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6952 - accuracy: 0.8388WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6936 - accuracy: 0.8392 - val_loss: 0.1881 - val_accuracy: 0.9460 - lr: 0.0010\n",
            "Epoch 32/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6881 - accuracy: 0.8405WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6868 - accuracy: 0.8407 - val_loss: 0.1503 - val_accuracy: 0.9550 - lr: 0.0010\n",
            "Epoch 33/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6986 - accuracy: 0.8423WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6972 - accuracy: 0.8427 - val_loss: 0.1590 - val_accuracy: 0.9520 - lr: 0.0010\n",
            "Epoch 34/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6543 - accuracy: 0.8481WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6531 - accuracy: 0.8484 - val_loss: 0.1256 - val_accuracy: 0.9617 - lr: 0.0010\n",
            "Epoch 35/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6685 - accuracy: 0.8467WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 61ms/step - loss: 0.6670 - accuracy: 0.8470 - val_loss: 0.1656 - val_accuracy: 0.9525 - lr: 0.0010\n",
            "Epoch 36/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6603 - accuracy: 0.8505WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6587 - accuracy: 0.8508 - val_loss: 0.3039 - val_accuracy: 0.9172 - lr: 0.0010\n",
            "Epoch 37/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6363 - accuracy: 0.8500WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6349 - accuracy: 0.8503 - val_loss: 0.1324 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 38/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6499 - accuracy: 0.8516WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6487 - accuracy: 0.8519 - val_loss: 0.1353 - val_accuracy: 0.9615 - lr: 0.0010\n",
            "Epoch 39/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6467 - accuracy: 0.8534WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6452 - accuracy: 0.8538 - val_loss: 0.1364 - val_accuracy: 0.9615 - lr: 0.0010\n",
            "Epoch 40/40\n",
            "226/227 [============================>.] - ETA: 0s - loss: 0.6239 - accuracy: 0.8562WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_dense_1_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "227/227 [==============================] - 14s 60ms/step - loss: 0.6226 - accuracy: 0.8565 - val_loss: 0.1345 - val_accuracy: 0.9628 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z27FUIOZ7Pmu"
      },
      "source": [
        "# # load testing data for model testing\n",
        "# x_test_data=np.array(pd.DataFrame(pd.read_csv('processed_test_set.csv')))\n",
        "\n",
        "# x_test_data=x_test_data.reshape((15000,56,56))\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import random\n",
        "\n",
        "# plt.imshow(x_test_data[random.randint(0,14999)], cmap=\"gray\")\n",
        "# plt.show()\n",
        "\n",
        "with open(\"images_test.pkl\",'rb') as f:\n",
        "  x_test_data = pickle.load(f)\n",
        "x_test = x_test_data.reshape(-1,56,56,1)\n",
        "# x_test /= 255"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akblV-f3FRHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651043b2-084f-4b5d-bc99-26d5885e885f"
      },
      "source": [
        "pickle.dump(model, open('model1.pkl', 'wb'))\n",
        "pickle.dump(model2, open('model2.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://e72e63aa-5425-4a0c-b01b-cedd7809f74e/assets\n",
            "INFO:tensorflow:Assets written to: ram://fcf3d2a5-7256-4792-bf75-3c2b64402221/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNiolOR9FTEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4f5c0e-0312-41a9-beba-4550eb072393"
      },
      "source": [
        "result2 = model2.predict(x_test, verbose=1)\n",
        "result2 = np.argmax(result2, axis = 1)\n",
        "print(result2[0:10])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 3s 5ms/step\n",
            "[19 11  9 11  9 24 14 18 22  6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-HWtVFbFUWi"
      },
      "source": [
        "# output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTM3iaKkFVND"
      },
      "source": [
        "# transform 0-9 number to string like 0100000000, 0000001000\n",
        "def transform_digit (num):\n",
        "    temp_list = np.zeros(10)\n",
        "    temp_list[num]=1\n",
        "    temp_list = temp_list.astype(int)\n",
        "    str1 = ''.join(str(i) for i in temp_list)\n",
        "    return str1\n",
        "\n",
        "# tranform 0-25 number to 26-bit string with the index at the num value to be 1\n",
        "def transform_letter (num):\n",
        "    temp_list = np.zeros(26)\n",
        "    temp_list[num] = 1\n",
        "    \n",
        "    temp_list = temp_list.astype(int)\n",
        "    str1 = ''.join(str(i) for i in temp_list)\n",
        "    return str1\n",
        "\n",
        "output = list()\n",
        "for i in range (0,result.shape[0]):\n",
        "    tempStr = transform_digit(result[i])+transform_letter(result2[i])\n",
        "    output.append([i,tempStr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X1J-q0LFWgC"
      },
      "source": [
        "df=pd.DataFrame(output)\n",
        "df.columns = ['# Id','Category']\n",
        "df.to_csv('result.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}